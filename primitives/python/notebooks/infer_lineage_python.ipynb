{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from networkx.algorithms import tree\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from lineage import similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a directory and return filename:df pairs\n",
    "def build_df_dict_dir(nb_dir):\n",
    "    dataset = {}\n",
    "    for file in glob.glob(nb_dir+'*.csv'):\n",
    "        csvfile = os.path.basename(file)\n",
    "        try:\n",
    "            dataset[csvfile] = pd.read_csv(file, index_col=0)\n",
    "        except (pd.parser.CParserError, UnicodeDecodeError) as e:\n",
    "            # Star Wars: encoding=\"ISO-8859-1\"\n",
    "            #df = pd.read_csv(\n",
    "            #\"http://math-info.hse.ru/f/2015-16/all-py/data/tariff2012.csv\",\n",
    "            #sep=';')\n",
    "            if(csvfile == 'StarWars.csv'):\n",
    "                dataset[csvfile] = pd.read_csv(file, encoding=\"ISO-8859-1\", index_col=0)\n",
    "            elif(csvfile == 'tariff2012.csv'):\n",
    "                dataset[csvfile] = pd.read_csv(file, sep=\";\", index_col=0)\n",
    "            else:\n",
    "                try:\n",
    "                    dataset[csvfile] = pd.read_csv(file, encoding=\"ISO-8859-1\")\n",
    "                except:\n",
    "                    print(\"Error reading file:\", file)\n",
    "            \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre Clustering Functions\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def exact_schema_cluster(df_dict):\n",
    "    clusters = defaultdict(list)\n",
    "    for fname, df in df_dict.items():\n",
    "        clusters[frozenset(df)].append(fname)\n",
    "    return clusters\n",
    "\n",
    "def write_clusters_to_file(clusters, cluster_file):\n",
    "    with open(cluster_file, 'w') as fp:\n",
    "        for i, cluster in enumerate(clusters.values()):\n",
    "            fp.write(\"%d,%d,%s\\n\" % (i, len(cluster), \",\".join(cluster)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_csv_graph(artifact_dir, g_truth):\n",
    "    missing_files = []\n",
    "    for node in g_truth.nodes():\n",
    "        if not os.path.exists(artifact_dir+node):\n",
    "            print(\"Missing File: \"+artifact_dir+node)\n",
    "            missing_files.append(node)\n",
    "    return missing_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from lineage import graphs, similarity\n",
    "import pandas as pd\n",
    "\n",
    "def lineage_inference(wf_dir, pre_cluster=False, index=True, threshold=0.0001):\n",
    "    \n",
    "    nb_name = os.path.basename(wf_dir)\n",
    "    if index:\n",
    "        artifact_dir = wf_dir+'/artifacts/'\n",
    "    else:\n",
    "        artifact_dir = wf_dir+'/artifacts_1/'\n",
    "    \n",
    "    result_dir = wf_dir+'/inferred/'\n",
    "    os.makedirs(result_dir, exist_ok=True)\n",
    "    schema_file = result_dir+'schema_matching.csv'\n",
    "    row_file = result_dir+'row_matching.csv'\n",
    "    cluster_file = result_dir+'clusters.csv'\n",
    "    \n",
    "    dataset = build_df_dict_dir(artifact_dir)\n",
    "    \n",
    "    # Run the inference\n",
    "    if pre_cluster:\n",
    "        pairwise_jaccard = []\n",
    "        clusters = exact_schema_cluster(dataset)\n",
    "        for cluster in clusters.values():\n",
    "            batch = {k: dataset[k] for k in cluster}\n",
    "            pw_batch = similarity.get_pairwise_similarity(batch, similarity.compute_jaccard_DF, threshold=threshold)\n",
    "            pairwise_jaccard.extend(pw_batch)\n",
    "    else:      \n",
    "        pairwise_jaccard = similarity.get_pairwise_similarity(dataset, similarity.compute_jaccard_DF, threshold=threshold)\n",
    "    \n",
    "    \n",
    "    pw_jaccard_graph = graphs.generate_pairwise_graph(pairwise_jaccard)\n",
    "    nx.to_pandas_adjacency(pw_jaccard_graph,weight='weight').to_csv(\n",
    "                                                result_dir+'cell_sim.csv')\n",
    "    \n",
    "    g_inferred = graphs.generate_spanning_tree(pw_jaccard_graph)\n",
    "    nx.write_edgelist(g_inferred,result_dir+'infered_mst_cell.csv',data=True)\n",
    "\n",
    "      \n",
    "    # Load Ground Truth:\n",
    "    g_truth = nx.read_gpickle(wf_dir+'/'+nb_name+'_gt_fixed.pkl')\n",
    "\n",
    "    missing_files = check_csv_graph(artifact_dir, g_truth)\n",
    "    \n",
    "    pr_df = pd.DataFrame(columns = ['nb_name', 'index', 'preclustering', 'distance_metric',\n",
    "                                        'edges_correct', 'edges_missing', 'edges_to_remove', \n",
    "                                        'precision', 'recall', 'F1', 'missing_files' ])\n",
    "    print('Writing Cluster File')\n",
    "    \n",
    "    write_clusters_to_file(exact_schema_cluster(dataset), result_dir+'clusters_with_filename.csv')\n",
    "    \n",
    "    #print(\"Adding Join Edges\")\n",
    "    #join_list = find_all_joins_df_dict(dataset)\n",
    "    #print(len(join_list), \"Join Edges Added\")\n",
    "    #g_inferred = add_join_edges(join_list, g_inferred)\n",
    "    \n",
    "    \n",
    "    #Check Join Precision/Recall\n",
    "    \n",
    "    #inferred_j_edges = []\n",
    "    #for join in join_list:\n",
    "    #    inferred_j_edges.append((join[0], join[2]))\n",
    "    #    inferred_j_edges.append((join[1], join[2]))\n",
    "    \n",
    "    \n",
    "    #write_join_candidates(join_list, result_dir+'join_candidates.csv')\n",
    "    \n",
    "    g_truth_j_edges = [(u,v) for u,v,d in g_truth.edges(data=True) \\\n",
    "                       if g_truth[u][v]['operation'] == 'merge' ]\n",
    "    \n",
    "    #print(get_join_precision_recall(g_truth_j_edges, inferred_j_edges))\n",
    "    \n",
    "    result = graphs.get_precision_recall(g_truth,g_inferred)\n",
    "\n",
    "    pr_df = pr_df.append({\n",
    "            'nb_name': nb_name,\n",
    "            'index': index,\n",
    "            'preclustering': pre_cluster,\n",
    "            'distance_metric': 'pandas_cell',\n",
    "            'edges_correct': len(result['correct_edges']),\n",
    "            'edges_missing': len(result['to_add']),\n",
    "            'edges_to_remove': len(result['to_remove']),\n",
    "            'precision': result['Precision'],\n",
    "            'recall': result['Recall'],\n",
    "            'F1': result['F1'],\n",
    "            'missing_files': len(missing_files)\n",
    "        }, ignore_index=True)\n",
    "    \n",
    "    return pr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/media/suhail/Data/experiments/reexec/res/'\n",
    "sample_wf = base_dir+'home-depot'\n",
    "artifact_dir = sample_wf+'/artifacts/'\n",
    "#dataset = build_df_dict_dir(artifact_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='graph pairs', max=105), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Writing Cluster File\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_name</th>\n",
       "      <th>index</th>\n",
       "      <th>preclustering</th>\n",
       "      <th>distance_metric</th>\n",
       "      <th>edges_correct</th>\n",
       "      <th>edges_missing</th>\n",
       "      <th>edges_to_remove</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>missing_files</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>home-depot</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      nb_name index preclustering distance_metric edges_correct edges_missing  \\\n",
       "0  home-depot  True         False     pandas_cell            11             3   \n",
       "\n",
       "  edges_to_remove  precision    recall        F1 missing_files  \n",
       "0               1   0.785714  0.916667  0.846154             0  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lineage_inference(sample_wf, pre_cluster=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_wf = '/home/suhail/Projects/relic/primitives/python/generator/dataset/20190802-112245'\n",
    "lineage_inference(sample_wf, pre_cluster=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Notebook Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_cluster_types = [False]\n",
    "index_types = [True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run for Multiple Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nb_331056',\n",
       " 'nb_23457',\n",
       " 'nb_33614',\n",
       " 'nb_316514',\n",
       " 'nb_386796',\n",
       " 'nb_266913',\n",
       " 'nb_417011',\n",
       " 'nb_269991',\n",
       " 'nb_495072',\n",
       " 'nb_315236',\n",
       " 'nb_484354',\n",
       " 'nb_986282',\n",
       " 'nb_639263']"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_list = [\n",
    "    'nb_331056',\n",
    "    'nb_23457',\n",
    "    # nb_336256', #\n",
    "    'nb_33614',\n",
    "    # 'nb_650868', #\n",
    "    'nb_316514',\n",
    "    'nb_386796',\n",
    "    'nb_266913',\n",
    "    'nb_417011',\n",
    "    'nb_269991',\n",
    "    'nb_495072',\n",
    "    'nb_315236',\n",
    "    'nb_484354',\n",
    "    #'nb_772851',\n",
    "    #'nb_924102',\n",
    "    #'nb_921915',\n",
    "    'nb_986282',\n",
    "    # 'nb_582525', #\n",
    "    'nb_639263',\n",
    "]\n",
    "\n",
    "#fakerdir = '/home/suhail/Projects/relic/primitives/python/generator/dataset/'\n",
    "\n",
    "#nb_list = [d for d in os.listdir(fakerdir) if os.path.isdir(os.path.join(fakerdir, d))]\n",
    "nb_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "7\n",
      "21\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "7\n",
      "10\n",
      "9\n",
      "20\n",
      "8\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# Copy nbfiles from source to destination\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "for f in nb_list:\n",
    "    full_name = f + '.ipynb'\n",
    "    src = '/media/suhail/Data/experiments/reexec/' + full_name\n",
    "    dst = base_dir+full_name+'/'+'artifacts/'\n",
    "    #print(dst)\n",
    "    print(len([file for file in glob.glob(dst+'*.csv')]))\n",
    "    #shutil.copy(src, dst, follow_symlinks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect statistics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_list = [\n",
    "    'nb_331056.ipynb',\n",
    "    'nb_495072.ipynb',\n",
    "    'nb_315236.ipynb',\n",
    "    'churn',\n",
    "    'githubviz',\n",
    "    'titanic'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9589dada20474d49b702a5d2c51ce11e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='notebook', max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='cluster', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='index', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='graph pairs', max=45), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Cluster File\n",
      "Adding Join Edges\n",
      "1 Join Edges Added\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='cluster', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='index', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='graph pairs', max=28), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Cluster File\n",
      "Adding Join Edges\n",
      "1 Join Edges Added\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='cluster', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='index', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='graph pairs', max=21), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Cluster File\n",
      "Adding Join Edges\n",
      "0 Join Edges Added\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='cluster', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='index', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='graph pairs', max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Cluster File\n",
      "Adding Join Edges\n",
      "0 Join Edges Added\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='cluster', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='index', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='graph pairs', max=21), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Cluster File\n",
      "Adding Join Edges\n",
      "8 Join Edges Added\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='cluster', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='index', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='graph pairs', max=78), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Cluster File\n",
      "Adding Join Edges\n",
      "7 Join Edges Added\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook, tqdm\n",
    "import glob\n",
    "\n",
    "all_pr_df = pd.DataFrame(columns = ['nb_name', 'index', 'preclustering', 'distance_metric',\n",
    "                                        'edges_correct', 'edges_missing', 'edges_to_remove', \n",
    "                                        'precision', 'recall', 'F1','missing_files' ])\n",
    "\n",
    "errors = []\n",
    "\n",
    "for nb in tqdm_notebook(nb_list, desc='notebook', leave=True):\n",
    "    nb_dir = ('/media/suhail/Data/experiments/reexec/res/'+nb)\n",
    "    # print('Processing:', nb_dir)\n",
    "    os.makedirs(nb_dir+'/inferred', exist_ok=True)\n",
    "\n",
    "    for cluster in tqdm_notebook(pre_cluster_types, desc='cluster', leave=False):\n",
    "        for index in tqdm_notebook(index_types,  desc='index', leave=False):\n",
    "            files = glob.glob(nb_dir+'/inferred/*')\n",
    "            for f in files:\n",
    "                os.remove(f)\n",
    "            try:\n",
    "                result_df = lineage_inference(nb_dir, index=index, pre_cluster=False)\n",
    "                all_pr_df = pd.concat([all_pr_df, result_df],ignore_index=True)\n",
    "            except FileNotFoundError as e:\n",
    "                errors.append((nb_dir, cluster,index))\n",
    "                pass\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb7e8e1bbbf7473da9bea0f98eb90446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='notebook', max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: /media/suhail/Data/experiments/reexec/res/nb_331056.ipynb\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pre_cluster_types' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-6c8a1b382468>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/inferred'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mcluster\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre_cluster_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cluster'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_types\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/inferred/*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pre_cluster_types' is not defined"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook, tqdm\n",
    "import glob\n",
    "\n",
    "all_pr_df = pd.DataFrame(columns = ['nb_name', 'index', 'preclustering', 'distance_metric',\n",
    "                                        'edges_correct', 'edges_missing', 'edges_to_remove', \n",
    "                                        'precision', 'recall', 'F1','missing_files' ])\n",
    "\n",
    "errors = []\n",
    "threshold = 0.001\n",
    "\n",
    "for nb in tqdm_notebook(nb_list, desc='notebook', leave=True):\n",
    "    nb_dir = (base_dir+nb)\n",
    "    print('Processing:', nb_dir)\n",
    "    os.makedirs(nb_dir+'/inferred', exist_ok=True)\n",
    "\n",
    "    for cluster in tqdm_notebook(pre_cluster_types, desc='cluster', leave=False):\n",
    "        for index in tqdm_notebook(index_types,  desc='index', leave=False):\n",
    "            files = glob.glob(nb_dir+'/inferred/*')\n",
    "            for f in files:\n",
    "                os.remove(f)\n",
    "            try:\n",
    "                result_df = lineage_inference(nb_dir, index=index, pre_cluster=True, threshold=threshold)\n",
    "                all_pr_df = pd.concat([all_pr_df, result_df],ignore_index=True)\n",
    "            except FileNotFoundError as e:\n",
    "                errors.append((nb_dir, cluster,index))\n",
    "                pass\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_name</th>\n",
       "      <th>index</th>\n",
       "      <th>preclustering</th>\n",
       "      <th>distance_metric</th>\n",
       "      <th>edges_correct</th>\n",
       "      <th>edges_missing</th>\n",
       "      <th>edges_to_remove</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>missing_files</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nb_331056.ipynb</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nb_495072.ipynb</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nb_315236.ipynb</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>churn</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>githubviz</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>titanic</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           nb_name index preclustering distance_metric edges_correct  \\\n",
       "0  nb_331056.ipynb  True         False     pandas_cell             3   \n",
       "1  nb_495072.ipynb  True         False     pandas_cell             6   \n",
       "2  nb_315236.ipynb  True         False     pandas_cell             4   \n",
       "3            churn  True         False     pandas_cell             2   \n",
       "4        githubviz  True         False     pandas_cell             6   \n",
       "5          titanic  True         False     pandas_cell             8   \n",
       "\n",
       "  edges_missing edges_to_remove  precision    recall        F1 missing_files  \n",
       "0             7               5   0.300000  0.375000  0.333333             0  \n",
       "1             1               1   0.857143  0.857143  0.857143             0  \n",
       "2             2               1   0.666667  0.800000  0.727273             0  \n",
       "3             3               0   0.400000  1.000000  0.571429             0  \n",
       "4             0               4   1.000000  0.600000  0.750000             0  \n",
       "5             4               7   0.666667  0.533333  0.592593             0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>versions</th>\n",
       "      <th>edges_correct</th>\n",
       "      <th>edges_missing</th>\n",
       "      <th>edges_to_remove</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6000x10</td>\n",
       "      <td>60</td>\n",
       "      <td>24</td>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.539326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100x10</td>\n",
       "      <td>55</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "      <td>10</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.577778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000x10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>184x50</td>\n",
       "      <td>55</td>\n",
       "      <td>23</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>0.425926</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.560976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000x20</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.588235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100x20</td>\n",
       "      <td>58</td>\n",
       "      <td>21</td>\n",
       "      <td>36</td>\n",
       "      <td>10</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.477273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100x10</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.514286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      size versions edges_correct edges_missing edges_to_remove  precision  \\\n",
       "0  6000x10       60            24            36               5   0.400000   \n",
       "1   100x10       55            26            28              10   0.481481   \n",
       "2  1000x10       10            10            10               5   0.500000   \n",
       "3   184x50       55            23            31               5   0.425926   \n",
       "4  1000x20       24            10            13               1   0.434783   \n",
       "5   100x20       58            21            36              10   0.368421   \n",
       "6   100x10       24             9            14               3   0.391304   \n",
       "\n",
       "     recall        F1  \n",
       "0  0.827586  0.539326  \n",
       "1  0.722222  0.577778  \n",
       "2  0.666667  0.571429  \n",
       "3  0.821429  0.560976  \n",
       "4  0.909091  0.588235  \n",
       "5  0.677419  0.477273  \n",
       "6  0.750000  0.514286  "
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dict = {'base_table_size': ['6000x10', '100x10', '1000x10', '184x50','1000x20', '100x20', '100x10'], 'versions' : ['60', '55', '10', '55','24', '58', '24']}\n",
    "all_pr_df['size'] = new_dict['base_table_size']\n",
    "all_pr_df['versions'] = new_dict['versions']\n",
    "all_pr_df[['size', 'versions', 'edges_correct', 'edges_missing', 'edges_to_remove', 'precision', 'recall', 'F1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading file: /home/suhail/Projects/relic/primitives/python/generator/dataset/20190802-112245/artifacts_1/18.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suhail/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: FutureWarning: pandas.parser is deprecated and will be removed in a future version.\n",
      "You can access CParserError as pandas.errors.ParserError\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='graph pairs', max=253), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suhail/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py:3755: RuntimeWarning: '<' not supported between instances of 'str' and 'float', sort order is undefined for incomparable objects\n",
      "  return this.join(other, how=how, return_indexers=return_indexers)\n",
      "/home/suhail/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py:3755: RuntimeWarning: '<' not supported between instances of 'str' and 'int', sort order is undefined for incomparable objects\n",
      "  return this.join(other, how=how, return_indexers=return_indexers)\n",
      "/home/suhail/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py:3755: RuntimeWarning: '<' not supported between instances of 'float' and 'str', sort order is undefined for incomparable objects\n",
      "  return this.join(other, how=how, return_indexers=return_indexers)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suhail/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py:3755: RuntimeWarning: '<' not supported between instances of 'int' and 'str', sort order is undefined for incomparable objects\n",
      "  return this.join(other, how=how, return_indexers=return_indexers)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_name</th>\n",
       "      <th>index</th>\n",
       "      <th>preclustering</th>\n",
       "      <th>distance_metric</th>\n",
       "      <th>edges_correct</th>\n",
       "      <th>edges_missing</th>\n",
       "      <th>edges_to_remove</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>missing_files</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20190802-112245</td>\n",
       "      <td>False</td>\n",
       "      <td>no_pre_cluster</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           nb_name  index   preclustering distance_metric edges_correct  \\\n",
       "0  20190802-112245  False  no_pre_cluster     pandas_cell            13   \n",
       "\n",
       "  edges_missing edges_to_remove  precision    recall    F1 missing_files  \n",
       "0            10               4   0.565217  0.764706  0.65             0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lineage_inference('/home/suhail/Projects/relic/primitives/python/generator/dataset/20190802-112245', index=False, pre_cluster='no_pre_cluster', threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nppo import *\n",
    "import os\n",
    "import networkx as nx\n",
    "\n",
    "def compare_edges(g_truth, g_inferred):\n",
    "    g_edge_set = set([frozenset((v1, v2)) for v1, v2 in g_truth.edges])\n",
    "    t_edge_set = set([frozenset((v1, v2)) for v1, v2 in g_inferred.edges])\n",
    "\n",
    "    correct = g_edge_set.intersection(t_edge_set)\n",
    "    \n",
    "    to_add  = g_edge_set - t_edge_set\n",
    "    to_remove = t_edge_set - g_edge_set\n",
    "    \n",
    "    return correct, to_add, to_remove\n",
    "\n",
    "\n",
    "def get_edge_operation(g_truth, edge):\n",
    "    # Edge is (u,v) pair\n",
    "    u,v = edge\n",
    "    if (u,v) in g_truth.edges:\n",
    "        return g_truth[u][v]['operation']\n",
    "    elif (v,u) in g_truth.edges:\n",
    "        return g_truth[v][u]['operation']\n",
    "\n",
    "def get_edge_weight(g_weights, edge):\n",
    "    # Edge is (u,v) pair\n",
    "    u,v = edge\n",
    "    if (u,v) in g_weights.edges:\n",
    "        return g_weights[u][v]['weight']\n",
    "    elif (v,u) in g_weights.edges:\n",
    "        return g_weights[v][u]['weight']\n",
    "\n",
    " \n",
    "def get_operational_accuracy(nb_dir):\n",
    "    nb_name = os.path.basename(nb_dir)\n",
    "    result_dir = nb_dir+'/inferred/'\n",
    "    \n",
    "    g_truth = nx.read_gpickle(nb_dir+'/'+nb_name+'_gt.pkl')\n",
    "    g_inferred = nx.read_edgelist(result_dir+'infered_mst_cell.csv')\n",
    "    \n",
    "    g_weights = nx.from_pandas_adjacency(pd.read_csv(result_dir+'cell_sim.csv', index_col=0)) \n",
    "    correct, to_add, to_remove = compare_edges(g_truth, g_inferred)\n",
    "    \n",
    "    correct_ops = [get_edge_operation(g_truth,(u,v)) for u,v in correct]\n",
    "    false_negatives = [((u,v), get_edge_operation(g_truth,(u,v)), get_edge_weight(g_weights, (u,v))) for u,v in to_add]\n",
    "    false_positives = [((u,v), get_edge_weight(g_weights, (u,v))) for u,v in to_remove]\n",
    "    \n",
    "    \n",
    "    missed_merges = [e for e in g_truth.edges(data=True) if e[2]['operation'] == 'merge']\n",
    "    \n",
    "    #get_all_joins_wf(nb_name, nb_dir+'/artifacts/')\n",
    "        \n",
    "    return missed_merges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2.csv', '4.csv', {'operation': 'merge'}),\n",
       " ('3.csv', '4.csv', {'operation': 'merge'}),\n",
       " ('4.csv', '31.csv', {'operation': 'merge'}),\n",
       " ('14.csv', '17.csv', {'operation': 'merge'}),\n",
       " ('14.csv', '27.csv', {'operation': 'merge'}),\n",
       " ('16.csv', '17.csv', {'operation': 'merge'}),\n",
       " ('17.csv', '20.csv', {'operation': 'merge'}),\n",
       " ('19.csv', '20.csv', {'operation': 'merge'}),\n",
       " ('22.csv', '29.csv', {'operation': 'merge'}),\n",
       " ('26.csv', '27.csv', {'operation': 'merge'}),\n",
       " ('28.csv', '29.csv', {'operation': 'merge'}),\n",
       " ('30.csv', '31.csv', {'operation': 'merge'}),\n",
       " ('30.csv', '42.csv', {'operation': 'merge'}),\n",
       " ('31.csv', '48.csv', {'operation': 'merge'}),\n",
       " ('32.csv', '36.csv', {'operation': 'merge'}),\n",
       " ('32.csv', '39.csv', {'operation': 'merge'}),\n",
       " ('35.csv', '36.csv', {'operation': 'merge'}),\n",
       " ('37.csv', '60.csv', {'operation': 'merge'}),\n",
       " ('38.csv', '39.csv', {'operation': 'merge'}),\n",
       " ('41.csv', '42.csv', {'operation': 'merge'}),\n",
       " ('47.csv', '48.csv', {'operation': 'merge'}),\n",
       " ('59.csv', '60.csv', {'operation': 'merge'})]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = get_operational_accuracy('/home/suhail/Projects/relic/primitives/python/generator/dataset/20190802-112317')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-68494d8d845b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmerge_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mop\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mmerge_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmerge_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "merge_dict = defaultdict(set)\n",
    "\n",
    "for u,v,op in result:\n",
    "    merge_dict[u].add(u)\n",
    "    merge_dict[u].add(v)\n",
    "    merge_dict[v].add(u)\n",
    "    merge_dict[v].add(v)\n",
    "\n",
    "merge_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'merge_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-b6f414d2e630>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjoin_combos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmerge_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mjoin_combos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'merge_dict' is not defined"
     ]
    }
   ],
   "source": [
    "join_combos = [u for u in merge_dict.values() if len(u) == 3]\n",
    "join_combos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = build_df_dict_dir(base_dir+'nb_315236.ipynb')\n",
    "#[evaluate_join_triple(combo, df_dict) for combo in join_combos]\n",
    "#df_dict['1.csv'][['ipv4_public', 'mac_processor']].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'31.csv', '47.csv', '48.csv'}\n",
      "Column Union Match: 48.csv ('31.csv', '47.csv')\n",
      "Checking column coherency of 31.csv 48.csv\n",
      "Checking column coherency of 47.csv 48.csv\n",
      "coherent: ('48.csv', ('31.csv', '47.csv'))\n",
      "intersection:  ('48.csv', ('31.csv', '47.csv'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('48.csv', ('31.csv', '47.csv'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_join_triple(join_combos[6], df_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'27.csv', '17.csv', '14.csv'}\n",
      "{'27.csv', '26.csv', '14.csv'}\n",
      "{'19.csv', '17.csv', '20.csv'}\n",
      "{'28.csv', '22.csv', '29.csv'}\n",
      "Column Union Match: 29.csv ('28.csv', '22.csv')\n",
      "Checking column coherency of 28.csv 29.csv\n",
      "Checking column coherency of 22.csv 29.csv\n",
      "coherent: ('29.csv', ('28.csv', '22.csv'))\n",
      "intersection:  ('29.csv', ('28.csv', '22.csv'))\n",
      "{'30.csv', '31.csv', '42.csv'}\n",
      "{'30.csv', '41.csv', '42.csv'}\n",
      "{'31.csv', '47.csv', '48.csv'}\n",
      "Column Union Match: 48.csv ('31.csv', '47.csv')\n",
      "Checking column coherency of 31.csv 48.csv\n",
      "Checking column coherency of 47.csv 48.csv\n",
      "coherent: ('48.csv', ('31.csv', '47.csv'))\n",
      "intersection:  ('48.csv', ('31.csv', '47.csv'))\n",
      "{'39.csv', '36.csv', '32.csv'}\n",
      "{'35.csv', '36.csv', '32.csv'}\n",
      "{'39.csv', '38.csv', '32.csv'}\n",
      "{'59.csv', '37.csv', '60.csv'}\n",
      "Column Union Match: 60.csv ('59.csv', '37.csv')\n",
      "Checking column coherency of 59.csv 60.csv\n",
      "Checking column coherency of 37.csv 60.csv\n",
      "coherent: ('60.csv', ('59.csv', '37.csv'))\n",
      "intersection:  ('60.csv', ('59.csv', '37.csv'))\n"
     ]
    }
   ],
   "source": [
    "for combo in join_combos:\n",
    "    evaluate_join_triple(combo, df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "%load_ext memory_profiler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_dict['47.csv']\n",
    "dest = df_dict['48.csv']\n",
    "df2 = df_dict['31.csv']\n",
    "\n",
    "#coherent_1 = get_max_coherent_columns(df1,dest)\n",
    "#coherent_2 = get_max_coherent_columns(df2,dest)\n",
    "#check_col_group_containment(df2,dest,['ipv4', 'ipv4_private', 'url', 'numerify', 'unix_time', 'bothify', 'suffix_female', 'pydecimal', 'bban'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'address',\n",
       " 'bban',\n",
       " 'boolean',\n",
       " 'city_suffix',\n",
       " 'country',\n",
       " 'credit_card_full',\n",
       " 'currency_code',\n",
       " 'date',\n",
       " 'ipv4_public',\n",
       " 'ipv6',\n",
       " 'language_code',\n",
       " 'mac_platform_token',\n",
       " 'mac_processor',\n",
       " 'null_boolean',\n",
       " 'prefix',\n",
       " 'pyfloat',\n",
       " 'pyint',\n",
       " 'random_digit_x',\n",
       " 'random_digit_y',\n",
       " 'random_number',\n",
       " 'rgb_color',\n",
       " 'sentence',\n",
       " 'state_abbr',\n",
       " 'street_address',\n",
       " 'uri',\n",
       " 'uri_page'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = generate_common_lattice(df2,dest)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Disambiguate _x and _y as left and right side join columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([s for s in itertools.combinations(s,26)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_pr_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-879b59399b48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_pr_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'all_pr_df' is not defined"
     ]
    }
   ],
   "source": [
    "all_pr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_name</th>\n",
       "      <th>index</th>\n",
       "      <th>preclustering</th>\n",
       "      <th>distance_metric</th>\n",
       "      <th>edges_correct</th>\n",
       "      <th>edges_missing</th>\n",
       "      <th>edges_to_remove</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>missing_files</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nb_266913.ipynb</td>\n",
       "      <td>True</td>\n",
       "      <td>no_pre_cluster</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nb_23457.ipynb</td>\n",
       "      <td>True</td>\n",
       "      <td>no_pre_cluster</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nb_495072.ipynb</td>\n",
       "      <td>True</td>\n",
       "      <td>no_pre_cluster</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nb_417011.ipynb</td>\n",
       "      <td>True</td>\n",
       "      <td>no_pre_cluster</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nb_315236.ipynb</td>\n",
       "      <td>True</td>\n",
       "      <td>no_pre_cluster</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nb_33614.ipynb</td>\n",
       "      <td>True</td>\n",
       "      <td>no_pre_cluster</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nb_269991.ipynb</td>\n",
       "      <td>True</td>\n",
       "      <td>no_pre_cluster</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nb_331056.ipynb</td>\n",
       "      <td>True</td>\n",
       "      <td>no_pre_cluster</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>nb_986282.ipynb</td>\n",
       "      <td>True</td>\n",
       "      <td>no_pre_cluster</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nb_386796.ipynb</td>\n",
       "      <td>True</td>\n",
       "      <td>no_pre_cluster</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>nb_484354.ipynb</td>\n",
       "      <td>True</td>\n",
       "      <td>no_pre_cluster</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>nb_639263.ipynb</td>\n",
       "      <td>True</td>\n",
       "      <td>no_pre_cluster</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            nb_name index   preclustering distance_metric edges_correct  \\\n",
       "4   nb_266913.ipynb  True  no_pre_cluster     pandas_cell             5   \n",
       "1    nb_23457.ipynb  True  no_pre_cluster     pandas_cell             4   \n",
       "7   nb_495072.ipynb  True  no_pre_cluster     pandas_cell             5   \n",
       "5   nb_417011.ipynb  True  no_pre_cluster     pandas_cell             4   \n",
       "8   nb_315236.ipynb  True  no_pre_cluster     pandas_cell             5   \n",
       "2    nb_33614.ipynb  True  no_pre_cluster     pandas_cell             9   \n",
       "6   nb_269991.ipynb  True  no_pre_cluster     pandas_cell             2   \n",
       "0   nb_331056.ipynb  True  no_pre_cluster     pandas_cell             4   \n",
       "10  nb_986282.ipynb  True  no_pre_cluster     pandas_cell             2   \n",
       "3   nb_386796.ipynb  True  no_pre_cluster     pandas_cell             1   \n",
       "9   nb_484354.ipynb  True  no_pre_cluster     pandas_cell             4   \n",
       "11  nb_639263.ipynb  True  no_pre_cluster     pandas_cell             1   \n",
       "\n",
       "   edges_missing edges_to_remove  precision    recall        F1 missing_files  \n",
       "4              1               1   0.833333  0.833333  0.833333             0  \n",
       "1              1               1   0.800000  0.800000  0.800000             0  \n",
       "7              4               1   0.555556  0.833333  0.666667             0  \n",
       "5              3               1   0.571429  0.800000  0.666667             0  \n",
       "8              3               2   0.625000  0.714286  0.666667             0  \n",
       "2             12               3   0.428571  0.750000  0.545455             0  \n",
       "6              4               2   0.333333  0.500000  0.400000             0  \n",
       "0              7               6   0.363636  0.400000  0.380952             0  \n",
       "10             4               4   0.333333  0.333333  0.333333             0  \n",
       "3              5               2   0.166667  0.333333  0.222222             0  \n",
       "9             18              10   0.181818  0.285714  0.222222             0  \n",
       "11             5               5   0.166667  0.166667  0.166667             0  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pr_df.sort_values('F1', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonindexed_cell = all_pr_df.loc[(all_pr_df.distance_metric == 'cell')\n",
    "                        & (all_pr_df['index'] == False)]\n",
    "nonindexed_col = all_pr_df.loc[(all_pr_df.distance_metric == 'col')\n",
    "                        & (all_pr_df['index'] == False)]\n",
    "#nonindexed_cell.to_excel('results_noindex_cell.xlsx')\n",
    "#nonindexed_col.to_excel('results_noindex_col.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_pr_df.to_excel('results.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CommandLine Debugging\n",
    "'''\n",
    "/home/suhail/Projects/relic/primitives/cpp/src/pre_clustering/pre_clustering -partial_schema -result /media/suhail/Data/experiments/results/ok/nb_639263.ipynb/inferred/ -schema_file /media/suhail/Data/experiments/results/ok/nb_639263.ipynb/inferred/schema_matching.csv\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_name</th>\n",
       "      <th>index</th>\n",
       "      <th>preclustering</th>\n",
       "      <th>distance_metric</th>\n",
       "      <th>edges_correct</th>\n",
       "      <th>edges_missing</th>\n",
       "      <th>edges_to_remove</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nb_331056.ipynb</td>\n",
       "      <td>True</td>\n",
       "      <td>no_pre_cluster</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nb_331056.ipynb</td>\n",
       "      <td>False</td>\n",
       "      <td>no_pre_cluster</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nb_23457.ipynb</td>\n",
       "      <td>True</td>\n",
       "      <td>no_pre_cluster</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nb_23457.ipynb</td>\n",
       "      <td>False</td>\n",
       "      <td>no_pre_cluster</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nb_33614.ipynb</td>\n",
       "      <td>True</td>\n",
       "      <td>no_pre_cluster</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.588235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nb_33614.ipynb</td>\n",
       "      <td>False</td>\n",
       "      <td>no_pre_cluster</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.482759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nb_316514.ipynb</td>\n",
       "      <td>True</td>\n",
       "      <td>no_pre_cluster</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nb_316514.ipynb</td>\n",
       "      <td>False</td>\n",
       "      <td>no_pre_cluster</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nb_386796.ipynb</td>\n",
       "      <td>True</td>\n",
       "      <td>no_pre_cluster</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>nb_386796.ipynb</td>\n",
       "      <td>False</td>\n",
       "      <td>no_pre_cluster</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>nb_266913.ipynb</td>\n",
       "      <td>True</td>\n",
       "      <td>no_pre_cluster</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>nb_266913.ipynb</td>\n",
       "      <td>False</td>\n",
       "      <td>no_pre_cluster</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>nb_417011.ipynb</td>\n",
       "      <td>True</td>\n",
       "      <td>no_pre_cluster</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>nb_417011.ipynb</td>\n",
       "      <td>False</td>\n",
       "      <td>no_pre_cluster</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>nb_269991.ipynb</td>\n",
       "      <td>True</td>\n",
       "      <td>no_pre_cluster</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>nb_269991.ipynb</td>\n",
       "      <td>False</td>\n",
       "      <td>no_pre_cluster</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>nb_495072.ipynb</td>\n",
       "      <td>True</td>\n",
       "      <td>no_pre_cluster</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>nb_495072.ipynb</td>\n",
       "      <td>False</td>\n",
       "      <td>no_pre_cluster</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>nb_315236.ipynb</td>\n",
       "      <td>True</td>\n",
       "      <td>no_pre_cluster</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>nb_315236.ipynb</td>\n",
       "      <td>False</td>\n",
       "      <td>no_pre_cluster</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>nb_484354.ipynb</td>\n",
       "      <td>True</td>\n",
       "      <td>no_pre_cluster</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.060606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>nb_484354.ipynb</td>\n",
       "      <td>False</td>\n",
       "      <td>no_pre_cluster</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>nb_772851.ipynb</td>\n",
       "      <td>True</td>\n",
       "      <td>no_pre_cluster</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>nb_772851.ipynb</td>\n",
       "      <td>False</td>\n",
       "      <td>no_pre_cluster</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>nb_986282.ipynb</td>\n",
       "      <td>True</td>\n",
       "      <td>no_pre_cluster</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>nb_986282.ipynb</td>\n",
       "      <td>False</td>\n",
       "      <td>no_pre_cluster</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>nb_639263.ipynb</td>\n",
       "      <td>True</td>\n",
       "      <td>no_pre_cluster</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>nb_639263.ipynb</td>\n",
       "      <td>False</td>\n",
       "      <td>no_pre_cluster</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            nb_name  index   preclustering distance_metric edges_correct  \\\n",
       "0   nb_331056.ipynb   True  no_pre_cluster     pandas_cell             5   \n",
       "1   nb_331056.ipynb  False  no_pre_cluster     pandas_cell             3   \n",
       "2    nb_23457.ipynb   True  no_pre_cluster     pandas_cell             4   \n",
       "3    nb_23457.ipynb  False  no_pre_cluster     pandas_cell             4   \n",
       "4    nb_33614.ipynb   True  no_pre_cluster     pandas_cell            10   \n",
       "5    nb_33614.ipynb  False  no_pre_cluster     pandas_cell             7   \n",
       "6   nb_316514.ipynb   True  no_pre_cluster     pandas_cell             3   \n",
       "7   nb_316514.ipynb  False  no_pre_cluster     pandas_cell             1   \n",
       "8   nb_386796.ipynb   True  no_pre_cluster     pandas_cell             1   \n",
       "9   nb_386796.ipynb  False  no_pre_cluster     pandas_cell             1   \n",
       "10  nb_266913.ipynb   True  no_pre_cluster     pandas_cell             5   \n",
       "11  nb_266913.ipynb  False  no_pre_cluster     pandas_cell             5   \n",
       "12  nb_417011.ipynb   True  no_pre_cluster     pandas_cell             4   \n",
       "13  nb_417011.ipynb  False  no_pre_cluster     pandas_cell             2   \n",
       "14  nb_269991.ipynb   True  no_pre_cluster     pandas_cell             2   \n",
       "15  nb_269991.ipynb  False  no_pre_cluster     pandas_cell             2   \n",
       "16  nb_495072.ipynb   True  no_pre_cluster     pandas_cell             5   \n",
       "17  nb_495072.ipynb  False  no_pre_cluster     pandas_cell             3   \n",
       "18  nb_315236.ipynb   True  no_pre_cluster     pandas_cell             4   \n",
       "19  nb_315236.ipynb  False  no_pre_cluster     pandas_cell             4   \n",
       "20  nb_484354.ipynb   True  no_pre_cluster     pandas_cell             1   \n",
       "21  nb_484354.ipynb  False  no_pre_cluster     pandas_cell             0   \n",
       "22  nb_772851.ipynb   True  no_pre_cluster     pandas_cell             4   \n",
       "23  nb_772851.ipynb  False  no_pre_cluster     pandas_cell             3   \n",
       "24  nb_986282.ipynb   True  no_pre_cluster     pandas_cell             2   \n",
       "25  nb_986282.ipynb  False  no_pre_cluster     pandas_cell             3   \n",
       "26  nb_639263.ipynb   True  no_pre_cluster     pandas_cell             1   \n",
       "27  nb_639263.ipynb  False  no_pre_cluster     pandas_cell             1   \n",
       "\n",
       "   edges_missing edges_to_remove  precision    recall        F1  \n",
       "0              7               5   0.416667  0.500000  0.454545  \n",
       "1              9               3   0.250000  0.500000  0.333333  \n",
       "2              1               1   0.800000  0.800000  0.800000  \n",
       "3              1               1   0.800000  0.800000  0.800000  \n",
       "4             11               3   0.476190  0.769231  0.588235  \n",
       "5             14               1   0.333333  0.875000  0.482759  \n",
       "6              5               1   0.375000  0.750000  0.500000  \n",
       "7              7               2   0.125000  0.333333  0.181818  \n",
       "8              5               1   0.166667  0.500000  0.250000  \n",
       "9              5               0   0.166667  1.000000  0.285714  \n",
       "10             1               1   0.833333  0.833333  0.833333  \n",
       "11             1               1   0.833333  0.833333  0.833333  \n",
       "12             3               1   0.571429  0.800000  0.666667  \n",
       "13             5               2   0.285714  0.500000  0.363636  \n",
       "14             4               2   0.333333  0.500000  0.400000  \n",
       "15             4               1   0.333333  0.666667  0.444444  \n",
       "16             4               1   0.555556  0.833333  0.666667  \n",
       "17             6               2   0.333333  0.600000  0.428571  \n",
       "18             4               1   0.500000  0.800000  0.615385  \n",
       "19             4               1   0.500000  0.800000  0.615385  \n",
       "20            21              10   0.045455  0.090909  0.060606  \n",
       "21            22               8   0.000000  0.000000  0.000000  \n",
       "22             9               9   0.307692  0.307692  0.307692  \n",
       "23            10               5   0.230769  0.375000  0.285714  \n",
       "24             4               3   0.333333  0.400000  0.363636  \n",
       "25             3               0   0.500000  1.000000  0.666667  \n",
       "26             5               5   0.166667  0.166667  0.166667  \n",
       "27             5               5   0.166667  0.166667  0.166667  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_name</th>\n",
       "      <th>index</th>\n",
       "      <th>preclustering</th>\n",
       "      <th>distance_metric</th>\n",
       "      <th>edges_correct</th>\n",
       "      <th>edges_missing</th>\n",
       "      <th>edges_to_remove</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(0, 8]</th>\n",
       "      <td>nb_386796.ipynb</td>\n",
       "      <td>True</td>\n",
       "      <td>no_pre_cluster</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(8, 16]</th>\n",
       "      <td>nb_495072.ipynb</td>\n",
       "      <td>True</td>\n",
       "      <td>no_pre_cluster</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(16, 24]</th>\n",
       "      <td>nb_986282.ipynb</td>\n",
       "      <td>True</td>\n",
       "      <td>no_pre_cluster</td>\n",
       "      <td>pandas_cell</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  nb_name  index   preclustering distance_metric  \\\n",
       "(0, 8]    nb_386796.ipynb   True  no_pre_cluster     pandas_cell   \n",
       "(8, 16]   nb_495072.ipynb   True  no_pre_cluster     pandas_cell   \n",
       "(16, 24]  nb_986282.ipynb   True  no_pre_cluster     pandas_cell   \n",
       "\n",
       "          edges_correct  edges_missing  edges_to_remove  precision  recall  \\\n",
       "(0, 8]               10             14                3   0.800000   0.875   \n",
       "(8, 16]               5              5                2   0.833333   1.000   \n",
       "(16, 24]              4             22               10   0.500000   0.800   \n",
       "\n",
       "                F1  \n",
       "(0, 8]    0.800000  \n",
       "(8, 16]   0.833333  \n",
       "(16, 24]  0.615385  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups = all_pr_df.groupby(pd.cut(all_pr_df.index, range(0,len(all_pr_df), 8)))\n",
    "groups.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb_name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nb_331056.ipynb</th>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb_23457.ipynb</th>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb_33614.ipynb</th>\n",
       "      <td>0.588235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb_316514.ipynb</th>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb_386796.ipynb</th>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb_266913.ipynb</th>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb_417011.ipynb</th>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb_269991.ipynb</th>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb_495072.ipynb</th>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb_315236.ipynb</th>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb_484354.ipynb</th>\n",
       "      <td>0.060606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb_772851.ipynb</th>\n",
       "      <td>0.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb_986282.ipynb</th>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb_639263.ipynb</th>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       F1\n",
       "nb_name                  \n",
       "nb_331056.ipynb  0.454545\n",
       "nb_23457.ipynb   0.800000\n",
       "nb_33614.ipynb   0.588235\n",
       "nb_316514.ipynb  0.500000\n",
       "nb_386796.ipynb  0.285714\n",
       "nb_266913.ipynb  0.833333\n",
       "nb_417011.ipynb  0.666667\n",
       "nb_269991.ipynb  0.444444\n",
       "nb_495072.ipynb  0.666667\n",
       "nb_315236.ipynb  0.615385\n",
       "nb_484354.ipynb  0.060606\n",
       "nb_772851.ipynb  0.307692\n",
       "nb_986282.ipynb  0.666667\n",
       "nb_639263.ipynb  0.166667"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_f1 = all_pr_df.groupby(['nb_name'], sort=False)['F1'].max().to_frame()\n",
    "best_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = all_pr_df.groupby(['nb_name'])['F1'].transform(max) == all_pr_df['F1']\n",
    "max_filter = all_pr_df.loc[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_filter = max_filter.loc[max_filter['F1'] != 0]\n",
    "len(max_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edges_correct</th>\n",
       "      <th>edges_missing</th>\n",
       "      <th>edges_to_remove</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nb_331056.ipynb</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb_23457.ipynb</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb_33614.ipynb</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.588235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb_316514.ipynb</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb_386796.ipynb</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb_266913.ipynb</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb_417011.ipynb</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb_269991.ipynb</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb_495072.ipynb</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb_315236.ipynb</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb_484354.ipynb</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.060606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb_772851.ipynb</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb_986282.ipynb</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb_639263.ipynb</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                edges_correct edges_missing edges_to_remove  precision  \\\n",
       "nb_name                                                                  \n",
       "nb_331056.ipynb             5             7               5   0.416667   \n",
       "nb_23457.ipynb              4             1               1   0.800000   \n",
       "nb_33614.ipynb             10            11               3   0.476190   \n",
       "nb_316514.ipynb             3             5               1   0.375000   \n",
       "nb_386796.ipynb             1             5               0   0.166667   \n",
       "nb_266913.ipynb             5             1               1   0.833333   \n",
       "nb_417011.ipynb             4             3               1   0.571429   \n",
       "nb_269991.ipynb             2             4               1   0.333333   \n",
       "nb_495072.ipynb             5             4               1   0.555556   \n",
       "nb_315236.ipynb             4             4               1   0.500000   \n",
       "nb_484354.ipynb             1            21              10   0.045455   \n",
       "nb_772851.ipynb             4             9               9   0.307692   \n",
       "nb_986282.ipynb             3             3               0   0.500000   \n",
       "nb_639263.ipynb             1             5               5   0.166667   \n",
       "\n",
       "                   recall        F1  \n",
       "nb_name                              \n",
       "nb_331056.ipynb  0.500000  0.454545  \n",
       "nb_23457.ipynb   0.800000  0.800000  \n",
       "nb_33614.ipynb   0.769231  0.588235  \n",
       "nb_316514.ipynb  0.750000  0.500000  \n",
       "nb_386796.ipynb  1.000000  0.285714  \n",
       "nb_266913.ipynb  0.833333  0.833333  \n",
       "nb_417011.ipynb  0.800000  0.666667  \n",
       "nb_269991.ipynb  0.666667  0.444444  \n",
       "nb_495072.ipynb  0.833333  0.666667  \n",
       "nb_315236.ipynb  0.800000  0.615385  \n",
       "nb_484354.ipynb  0.090909  0.060606  \n",
       "nb_772851.ipynb  0.307692  0.307692  \n",
       "nb_986282.ipynb  1.000000  0.666667  \n",
       "nb_639263.ipynb  0.166667  0.166667  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_nb_scores = max_filter.drop(['index','preclustering','distance_metric'],axis=1)\n",
    "top_nb_scores = top_nb_scores.set_index('nb_name')\n",
    "top_nb_scores = top_nb_scores.drop_duplicates()\n",
    "top_nb_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     11\n",
       "False     7\n",
       "Name: index, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_filter['index'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c75ce7f97a96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwrite_clusters_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexact_schema_cluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'/home/suhail/Projects/relic/primitives/python/generator/dataset/20190802-112245/inferred/clusters_with_filename.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_dict' is not defined"
     ]
    }
   ],
   "source": [
    "write_clusters_to_file(exact_schema_cluster(df_dict),'/home/suhail/Projects/relic/primitives/python/generator/dataset/20190802-112245/inferred/clusters_with_filename.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = build_df_dict_dir(artifact_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {frozenset({'Unnamed: 0.1',\n",
       "                        'code',\n",
       "                        'level',\n",
       "                        'name',\n",
       "                        'name_en',\n",
       "                        'name_es',\n",
       "                        'name_short_en',\n",
       "                        'name_short_es',\n",
       "                        'parent_id'}): ['MexHS.csv', 'MexHS__1.csv'],\n",
       "             frozenset({'Unnamed: 0.1',\n",
       "                        'code',\n",
       "                        'level',\n",
       "                        'name',\n",
       "                        'parent_id'}): ['HSdf.csv'],\n",
       "             frozenset({'code', 'level', 'name', 'parent_id'}): ['HSdf__1.csv',\n",
       "              'AtlasHS.csv'],\n",
       "             frozenset({'Unnamed: 0.1',\n",
       "                        'code',\n",
       "                        'level_colatlas',\n",
       "                        'level_mex',\n",
       "                        'name_colatlas',\n",
       "                        'name_en',\n",
       "                        'name_es',\n",
       "                        'name_mex',\n",
       "                        'name_short_en',\n",
       "                        'name_short_es',\n",
       "                        'parent_id_colatlas',\n",
       "                        'parent_id_mex'}): ['AtlasHS_WithNoMexican.csv',\n",
       "              'AtlasHSWithMexMerge.csv']})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters=exact_schema_cluster(df_dict)\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_join_order(combo):\n",
    "    sizes = {x: len(x) for x in combo}\n",
    "    if max(sizes.values())==min(sizes.values()):\n",
    "        return None\n",
    "    join_dest = list(sizes.keys())[list(sizes.values()).index(max(sizes.values()))] \n",
    "    join_sources = tuple(x for x in combo if x is not join_dest)\n",
    "    \n",
    "    if join_sources[0].union(join_sources[1]) == join_dest:\n",
    "        return join_sources, join_dest\n",
    "    \n",
    "    return None\n",
    "\n",
    "def find_join_order_general(combo):\n",
    "    combo_set = set(combo)\n",
    "    max_combo = None\n",
    "    max_col_number = 0\n",
    "    for join_dest in combo_set:\n",
    "        join_sources = combo_set - set([join_dest])\n",
    "\n",
    "        common_cols = set()\n",
    "        for source in join_sources:\n",
    "            common_cols = common_cols.union(source)\n",
    "            \n",
    "        common_cols = common_cols.intersection(join_dest)\n",
    "        if not common_cols:\n",
    "            return None\n",
    "\n",
    "        if len(common_cols) > max_col_number:\n",
    "            max_col_number = len(common_cols)\n",
    "            max_combo = (tuple(join_sources), join_dest)\n",
    "            \n",
    "    return tuple(max_combo), len(common_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def find_join_schemas(clusters):\n",
    "    schema_combos = [combo for combo in itertools.combinations(clusters.keys(),3)]\n",
    "    join_schemas = []\n",
    "    for x in schema_combos:\n",
    "        #result = find_join_order(x)\n",
    "        result = find_join_order_general(x)\n",
    "        if result:\n",
    "            join_schemas.append(result)\n",
    "    return join_schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Fix this\n",
    "def find_join_schemas_maximal(clusters):\n",
    "    schema_combos = [combo for combo in itertools.combinations(clusters.keys(),3)]\n",
    "    join_schemas = defaultdict(lambda: defaultdict(list))\n",
    "    for x in schema_combos:\n",
    "        #result = find_join_order(x)\n",
    "        #print(type(x), x)\n",
    "        result = find_join_order_general(x)\n",
    "        if result:\n",
    "            combo, val = result\n",
    "            join_result = combo[1]\n",
    "            join_schemas[join_result][val].append(combo)\n",
    "    return join_schemas\n",
    "\n",
    "def prune_join_schemas(join_schemas):\n",
    "    pruned_candidates = []\n",
    "    for join_result in join_schemas.keys():\n",
    "        max_common_col = max(join_schemas[join_result])\n",
    "        print(max_common_col)\n",
    "        pruned_candidates.append(join_schemas[join_result][max_common_col])\n",
    "    \n",
    "    return pruned_candidates\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.find_join_schemas_maximal.<locals>.<lambda>()>,\n",
       "            {frozenset({'Unnamed: 0.1',\n",
       "                        'code',\n",
       "                        'level',\n",
       "                        'name',\n",
       "                        'parent_id'}): defaultdict(list,\n",
       "                         {5: [((frozenset({'code',\n",
       "                                        'level',\n",
       "                                        'name',\n",
       "                                        'parent_id'}),\n",
       "                             frozenset({'Unnamed: 0.1',\n",
       "                                        'code',\n",
       "                                        'level',\n",
       "                                        'name',\n",
       "                                        'name_en',\n",
       "                                        'name_es',\n",
       "                                        'name_short_en',\n",
       "                                        'name_short_es',\n",
       "                                        'parent_id'})),\n",
       "                            frozenset({'Unnamed: 0.1',\n",
       "                                       'code',\n",
       "                                       'level',\n",
       "                                       'name',\n",
       "                                       'parent_id'}))],\n",
       "                          2: [((frozenset({'code',\n",
       "                                        'level',\n",
       "                                        'name',\n",
       "                                        'parent_id'}),\n",
       "                             frozenset({'Unnamed: 0.1',\n",
       "                                        'code',\n",
       "                                        'level_colatlas',\n",
       "                                        'level_mex',\n",
       "                                        'name_colatlas',\n",
       "                                        'name_en',\n",
       "                                        'name_es',\n",
       "                                        'name_mex',\n",
       "                                        'name_short_en',\n",
       "                                        'name_short_es',\n",
       "                                        'parent_id_colatlas',\n",
       "                                        'parent_id_mex'})),\n",
       "                            frozenset({'Unnamed: 0.1',\n",
       "                                       'code',\n",
       "                                       'level',\n",
       "                                       'name',\n",
       "                                       'parent_id'}))]}),\n",
       "             frozenset({'Unnamed: 0.1',\n",
       "                        'code',\n",
       "                        'level',\n",
       "                        'name',\n",
       "                        'name_en',\n",
       "                        'name_es',\n",
       "                        'name_short_en',\n",
       "                        'name_short_es',\n",
       "                        'parent_id'}): defaultdict(list,\n",
       "                         {6: [((frozenset({'Unnamed: 0.1',\n",
       "                                        'code',\n",
       "                                        'level',\n",
       "                                        'name',\n",
       "                                        'parent_id'}),\n",
       "                             frozenset({'Unnamed: 0.1',\n",
       "                                        'code',\n",
       "                                        'level_colatlas',\n",
       "                                        'level_mex',\n",
       "                                        'name_colatlas',\n",
       "                                        'name_en',\n",
       "                                        'name_es',\n",
       "                                        'name_mex',\n",
       "                                        'name_short_en',\n",
       "                                        'name_short_es',\n",
       "                                        'parent_id_colatlas',\n",
       "                                        'parent_id_mex'})),\n",
       "                            frozenset({'Unnamed: 0.1',\n",
       "                                       'code',\n",
       "                                       'level',\n",
       "                                       'name',\n",
       "                                       'name_en',\n",
       "                                       'name_es',\n",
       "                                       'name_short_en',\n",
       "                                       'name_short_es',\n",
       "                                       'parent_id'})),\n",
       "                           ((frozenset({'code', 'level', 'name', 'parent_id'}),\n",
       "                             frozenset({'Unnamed: 0.1',\n",
       "                                        'code',\n",
       "                                        'level_colatlas',\n",
       "                                        'level_mex',\n",
       "                                        'name_colatlas',\n",
       "                                        'name_en',\n",
       "                                        'name_es',\n",
       "                                        'name_mex',\n",
       "                                        'name_short_en',\n",
       "                                        'name_short_es',\n",
       "                                        'parent_id_colatlas',\n",
       "                                        'parent_id_mex'})),\n",
       "                            frozenset({'Unnamed: 0.1',\n",
       "                                       'code',\n",
       "                                       'level',\n",
       "                                       'name',\n",
       "                                       'name_en',\n",
       "                                       'name_es',\n",
       "                                       'name_short_en',\n",
       "                                       'name_short_es',\n",
       "                                       'parent_id'}))]})})"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_join_schemas_maximal(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_schemas = find_join_schemas(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_schemas = find_join_schemas_maximal(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.find_join_schemas_maximal.<locals>.<lambda>()>,\n",
       "            {frozenset({'Unnamed: 0.1',\n",
       "                        'code',\n",
       "                        'level',\n",
       "                        'name',\n",
       "                        'parent_id'}): defaultdict(list,\n",
       "                         {5: [((frozenset({'code',\n",
       "                                        'level',\n",
       "                                        'name',\n",
       "                                        'parent_id'}),\n",
       "                             frozenset({'Unnamed: 0.1',\n",
       "                                        'code',\n",
       "                                        'level',\n",
       "                                        'name',\n",
       "                                        'name_en',\n",
       "                                        'name_es',\n",
       "                                        'name_short_en',\n",
       "                                        'name_short_es',\n",
       "                                        'parent_id'})),\n",
       "                            frozenset({'Unnamed: 0.1',\n",
       "                                       'code',\n",
       "                                       'level',\n",
       "                                       'name',\n",
       "                                       'parent_id'}))],\n",
       "                          2: [((frozenset({'code',\n",
       "                                        'level',\n",
       "                                        'name',\n",
       "                                        'parent_id'}),\n",
       "                             frozenset({'Unnamed: 0.1',\n",
       "                                        'code',\n",
       "                                        'level_colatlas',\n",
       "                                        'level_mex',\n",
       "                                        'name_colatlas',\n",
       "                                        'name_en',\n",
       "                                        'name_es',\n",
       "                                        'name_mex',\n",
       "                                        'name_short_en',\n",
       "                                        'name_short_es',\n",
       "                                        'parent_id_colatlas',\n",
       "                                        'parent_id_mex'})),\n",
       "                            frozenset({'Unnamed: 0.1',\n",
       "                                       'code',\n",
       "                                       'level',\n",
       "                                       'name',\n",
       "                                       'parent_id'}))]}),\n",
       "             frozenset({'Unnamed: 0.1',\n",
       "                        'code',\n",
       "                        'level',\n",
       "                        'name',\n",
       "                        'name_en',\n",
       "                        'name_es',\n",
       "                        'name_short_en',\n",
       "                        'name_short_es',\n",
       "                        'parent_id'}): defaultdict(list,\n",
       "                         {6: [((frozenset({'Unnamed: 0.1',\n",
       "                                        'code',\n",
       "                                        'level',\n",
       "                                        'name',\n",
       "                                        'parent_id'}),\n",
       "                             frozenset({'Unnamed: 0.1',\n",
       "                                        'code',\n",
       "                                        'level_colatlas',\n",
       "                                        'level_mex',\n",
       "                                        'name_colatlas',\n",
       "                                        'name_en',\n",
       "                                        'name_es',\n",
       "                                        'name_mex',\n",
       "                                        'name_short_en',\n",
       "                                        'name_short_es',\n",
       "                                        'parent_id_colatlas',\n",
       "                                        'parent_id_mex'})),\n",
       "                            frozenset({'Unnamed: 0.1',\n",
       "                                       'code',\n",
       "                                       'level',\n",
       "                                       'name',\n",
       "                                       'name_en',\n",
       "                                       'name_es',\n",
       "                                       'name_short_en',\n",
       "                                       'name_short_es',\n",
       "                                       'parent_id'})),\n",
       "                           ((frozenset({'code', 'level', 'name', 'parent_id'}),\n",
       "                             frozenset({'Unnamed: 0.1',\n",
       "                                        'code',\n",
       "                                        'level_colatlas',\n",
       "                                        'level_mex',\n",
       "                                        'name_colatlas',\n",
       "                                        'name_en',\n",
       "                                        'name_es',\n",
       "                                        'name_mex',\n",
       "                                        'name_short_en',\n",
       "                                        'name_short_es',\n",
       "                                        'parent_id_colatlas',\n",
       "                                        'parent_id_mex'})),\n",
       "                            frozenset({'Unnamed: 0.1',\n",
       "                                       'code',\n",
       "                                       'level',\n",
       "                                       'name',\n",
       "                                       'name_en',\n",
       "                                       'name_es',\n",
       "                                       'name_short_en',\n",
       "                                       'name_short_es',\n",
       "                                       'parent_id'}))]})})"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "pruned = prune_join_schemas(join_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[((frozenset({'code', 'level', 'name', 'parent_id'}),\n",
       "    frozenset({'Unnamed: 0.1',\n",
       "               'code',\n",
       "               'level',\n",
       "               'name',\n",
       "               'name_en',\n",
       "               'name_es',\n",
       "               'name_short_en',\n",
       "               'name_short_es',\n",
       "               'parent_id'})),\n",
       "   frozenset({'Unnamed: 0.1', 'code', 'level', 'name', 'parent_id'}))],\n",
       " [((frozenset({'Unnamed: 0.1', 'code', 'level', 'name', 'parent_id'}),\n",
       "    frozenset({'Unnamed: 0.1',\n",
       "               'code',\n",
       "               'level_colatlas',\n",
       "               'level_mex',\n",
       "               'name_colatlas',\n",
       "               'name_en',\n",
       "               'name_es',\n",
       "               'name_mex',\n",
       "               'name_short_en',\n",
       "               'name_short_es',\n",
       "               'parent_id_colatlas',\n",
       "               'parent_id_mex'})),\n",
       "   frozenset({'Unnamed: 0.1',\n",
       "              'code',\n",
       "              'level',\n",
       "              'name',\n",
       "              'name_en',\n",
       "              'name_es',\n",
       "              'name_short_en',\n",
       "              'name_short_es',\n",
       "              'parent_id'})),\n",
       "  ((frozenset({'code', 'level', 'name', 'parent_id'}),\n",
       "    frozenset({'Unnamed: 0.1',\n",
       "               'code',\n",
       "               'level_colatlas',\n",
       "               'level_mex',\n",
       "               'name_colatlas',\n",
       "               'name_en',\n",
       "               'name_es',\n",
       "               'name_mex',\n",
       "               'name_short_en',\n",
       "               'name_short_es',\n",
       "               'parent_id_colatlas',\n",
       "               'parent_id_mex'})),\n",
       "   frozenset({'Unnamed: 0.1',\n",
       "              'code',\n",
       "              'level',\n",
       "              'name',\n",
       "              'name_en',\n",
       "              'name_es',\n",
       "              'name_short_en',\n",
       "              'name_short_es',\n",
       "              'parent_id'}))]]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def enumerate_join_candidates(join_schemas, clusters, df_dict):\n",
    "    join_candidates = []\n",
    "    for schema in join_schemas:\n",
    "        join_l, join_r = clusters[schema[0][0]], clusters[schema[0][1]]\n",
    "        join_dest = clusters[schema[1]]\n",
    "        for jl in join_l:\n",
    "            for jr in join_r:\n",
    "                for jd in join_dest:\n",
    "                    coherent_1 = simple_coherency_check(df_dict[jd],df_dict[jl])\n",
    "                    coherent_2 = simple_coherency_check(df_dict[jd],df_dict[jr])\n",
    "                    # Check if the coherent columns generate the output set\n",
    "                    if coherent_1 and coherent_2:\n",
    "                        if set(coherent_1).union(set(coherent_2)) == set(df_dict[jd]):\n",
    "                            if set(coherent_1).intersection(set(coherent_2)): # Check if the intersection is not null\n",
    "                                join_candidates.append((jl,jr,jd))\n",
    "    return join_candidates\n",
    "\n",
    "\n",
    "def enumerate_join_candidates_new(join_schemas, clusters, df_dict):\n",
    "    candidates = {}\n",
    "    \n",
    "    for schema in join_schemas:\n",
    "        max_join_union_size = 0\n",
    "        join_candidates = defaultdict(list)\n",
    "        #print(schema)\n",
    "        join_l, join_r = clusters[schema[0][0][0]], clusters[schema[0][0][1]]\n",
    "        join_dest = clusters[schema[0][1]]\n",
    "        for jl in join_l:\n",
    "            for jr in join_r:\n",
    "                for jd in join_dest:\n",
    "                    coherent_1 = simple_coherency_check(df_dict[jd],df_dict[jl])\n",
    "                    coherent_2 = simple_coherency_check(df_dict[jd],df_dict[jr])\n",
    "                    # Check if the coherent columns generate the output set\n",
    "                    # TODO: Check Maximal column containment and atleast one intersection\n",
    "                    print(coherent_1, coherent_2)\n",
    "                    if coherent_1 and coherent_2:\n",
    "                        #if set(coherent_1).union(set(coherent_2)) == set(df_dict[jd]):\n",
    "                        #    if set(coherent_1).intersection(set(coherent_2)): # Check if the intersection is not null\n",
    "                        #        join_candidates.append((jl,jr,jd))\n",
    "                        \n",
    "                        union = set(coherent_1).union(set(coherent_2))\n",
    "                        size = len(union.intersection(set(df_dict[jd])))\n",
    "                        if size > 0 and size >= max_join_union_size:\n",
    "                            if set(coherent_1).intersection(set(coherent_2)): # Check if the intersection is not null\n",
    "                                join_candidates[size].append((jl,jr,jd))\n",
    "                                max_join_union_size = size\n",
    "                    \n",
    "        candidates[schema[0]] = join_candidates[max_join_union_size]\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def check_minimal_extra_values(candidates, df_dict):\n",
    "    # For each schema pair, check for values that should have been joined but are not\n",
    "    # present\n",
    "    best_join_candidates = {}\n",
    "    for schema, candidate_list in candidates.items():\n",
    "        #Set Difference\n",
    "        best_matches = defaultdict(list)\n",
    "        least_surplus = np.inf\n",
    "        for combo in candidate_list:\n",
    "            jl,jr,jd = combo\n",
    "            coherent_l = simple_coherency_check(df_dict[jd],df_dict[jl])\n",
    "            coherent_r = simple_coherency_check(df_dict[jd],df_dict[jr])\n",
    "            \n",
    "            jlvalset = set(frozenset(u) for u in df_dict[jl][list(coherent_l)].values.tolist())\n",
    "            jrvalset = set(frozenset(u) for u in df_dict[jr][list(coherent_r)].values.tolist())\n",
    "            jdlvalset = set(frozenset(u) for u in df_dict[jd][list(coherent_l)].values.tolist())\n",
    "            jdrvalset = set(frozenset(u) for u in df_dict[jd][list(coherent_r)].values.tolist())\n",
    "\n",
    "            \n",
    "            left_size = len(jlvalset - jdlvalset)\n",
    "            right_size = len(jrvalset - jdrvalset)\n",
    "            \n",
    "            total_excess = left_size + right_size\n",
    "            \n",
    "            if total_excess <= least_surplus:\n",
    "                best_matches[total_excess].append((jl,jr,jd))\n",
    "                least_surplus = total_excess\n",
    "            \n",
    "        best_join_candidates[schema] = best_matches[least_surplus]\n",
    "\n",
    "    return best_join_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nppo\n",
    "import csv\n",
    "\n",
    "def simple_coherency_check(base_df, join_dest_df):\n",
    "    return nppo.get_max_coherent_columns_1(base_df, join_dest_df)\n",
    "    \n",
    "def write_join_candidates(join_candidate_list, filename):\n",
    "    with open(filename,'w') as fp:\n",
    "        csv_out = csv.writer(fp)\n",
    "        for row in join_candidate_list:\n",
    "            csv_out.writerow(row)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({'domain_name',\n",
       "           'ipv4_private',\n",
       "           'ipv4_public',\n",
       "           'military_apo',\n",
       "           'military_dpo',\n",
       "           'numerify',\n",
       "           'pyint',\n",
       "           'ssn',\n",
       "           'unix_partition'})"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DEBUG\n",
    "\n",
    "schema = [((frozenset({'random_digit', 'ean8', 'numerify', 'prefix_male', 'pybool', 'url', 'randomize_nb_elements', 'random_number', 'ipv4_public'}), frozenset({'msisdn', 'state', 'invalid_ssn', 'domain_name', 'random_int', 'firefox', 'ssn', 'military_apo', 'military_dpo', 'prefix', 'ascii_free_email', 'password', 'zipcode_in_state', 'catch_phrase', 'numerify', 'unix_partition', 'cryptocurrency_code', 'day_of_week', 'pydecimal', 'ipv4_public', 'pyint', 'credit_card_full', 'ascii_safe_email', 'pyfloat', 'ipv4_private', 'last_name'})), frozenset({'ssn', 'military_apo', 'pyint', 'military_dpo', 'numerify', 'unix_partition', 'domain_name', 'ipv4_private', 'ipv4_public'}))]\n",
    "\n",
    "schema[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code', 'name', 'level'} None\n",
      "{'code', 'name', 'level'} None\n",
      "None None\n",
      "None None\n",
      "{'Unnamed: 0.1'} None\n",
      "None None\n",
      "{'Unnamed: 0.1'} None\n",
      "None None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_values([[], []])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jc = enumerate_join_candidates_new(pruned, clusters, df_dict)\n",
    "jc.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "jc_pruned = {k:v for k,v in jc.items() if len(v) > 0}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('12.csv', '18.csv', '19.csv')],\n",
       " [('8.csv', '19.csv', '9.csv')],\n",
       " [('2.csv', '19.csv', '12.csv'), ('0.csv', '19.csv', '12.csv')],\n",
       " [('6.csv', '22.csv', '23.csv')],\n",
       " [('1.csv', '13.csv', '14.csv'), ('16.csv', '13.csv', '14.csv')],\n",
       " [('10.csv', '23.csv', '22.csv')]]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_result = check_minimal_extra_values(jc_pruned, df_dict)\n",
    "[val for val in best_result.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('12.csv', '18.csv', '19.csv'),\n",
       " ('8.csv', '19.csv', '9.csv'),\n",
       " ('2.csv', '19.csv', '12.csv'),\n",
       " ('0.csv', '19.csv', '12.csv'),\n",
       " ('6.csv', '22.csv', '23.csv'),\n",
       " ('1.csv', '13.csv', '14.csv'),\n",
       " ('16.csv', '13.csv', '14.csv'),\n",
       " ('10.csv', '23.csv', '22.csv')]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_list = []\n",
    "for val in best_result.values():\n",
    "    final_list.extend(val)\n",
    "    \n",
    "final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 1\n",
      "3 1\n",
      "2 2\n",
      "9 1\n",
      "5 2\n",
      "1 1\n"
     ]
    }
   ],
   "source": [
    "for schema, candidates in jc_pruned.items():\n",
    "    print(len(candidates), len(best_result[schema]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_joins_df_dict(df_dict):\n",
    "    clusters=exact_schema_cluster(df_dict)\n",
    "    join_schemas = find_join_schemas_maximal(clusters)\n",
    "    pruned = prune_join_schemas(join_schemas)\n",
    "    jc = enumerate_join_candidates_new(pruned, clusters, df_dict)\n",
    "    jc_pruned = {k:v for k,v in jc.items() if len(v) > 0}\n",
    "    best_result = check_minimal_extra_values(jc_pruned, df_dict)\n",
    "    final_list = []\n",
    "    for val in best_result.values():\n",
    "        final_list.extend(val)\n",
    "\n",
    "    return final_list\n",
    "\n",
    "\n",
    "def add_join_edges(join_list, G):\n",
    "    for join in join_list:\n",
    "        G.add_edge(join[0], join[2], weight=0)\n",
    "        G.add_edge(join[1], join[2], weight=0)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_join_precision_recall(G_truth_edges, T_inferred_edges):\n",
    "    g_edge_set = set([frozenset((v1, v2)) for v1, v2 in G_truth_edges])\n",
    "    t_edge_set = set([frozenset((v1, v2)) for v1, v2 in T_inferred_edges])\n",
    "\n",
    "    correct = g_edge_set.intersection(t_edge_set)\n",
    "    \n",
    "    to_add  = g_edge_set - t_edge_set\n",
    "    to_remove = t_edge_set - g_edge_set\n",
    "    \n",
    "    try:\n",
    "        precision = float(len(correct))/len(g_edge_set)\n",
    "        recall = float(len(correct))/len(t_edge_set)\n",
    "        f1 = 2 * ((precision * recall) / (precision + recall))\n",
    "    except ZeroDivisionError as e:\n",
    "        precision = 0.0\n",
    "        recall = 0.0\n",
    "        f1 = 0.0\n",
    "    \n",
    "    return {'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1': f1,\n",
    "            'correct_edges': correct,\n",
    "            'to_add': to_add,\n",
    "            'to_remove': to_remove}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_join_candidates(final_list,'/home/suhail/Projects/relic/primitives/python/generator/dataset/20190802-112245/inferred/join_candidates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
