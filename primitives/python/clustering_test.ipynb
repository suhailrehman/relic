{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '/media/suhail/Data/experiments/reexec/res/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_NAME = 'nb_331056.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from lineage import similarity, graphs\n",
    "\n",
    "import dataset as ds\n",
    "import clustering\n",
    "\n",
    "import nppo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = ds.build_df_dict_dir(BASE_DIR+NB_NAME+'/artifacts/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Schema, Df and index lists\n",
    "dfs = []\n",
    "schemas = []\n",
    "for name, df in df_dict.items():\n",
    "    dfs.append(name)\n",
    "    schemas.append(frozenset(df))\n",
    "\n",
    "indices = np.arange(len(schemas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance Metric\n",
    "def set_jaccard_distance(set1,set2):\n",
    "    intersect = set1.intersection(set2)\n",
    "    union = set1.union(set2)\n",
    "    return 1-(len(intersect)/len(union))\n",
    "\n",
    "#set_jaccard_distance(schemas[0],schemas[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  1,  0,  1,  1,  1, -1,  1,  1])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "def jacc_metric(x, y):\n",
    "    i, j = int(x[0]), int(y[0])     # extract indices\n",
    "    return set_jaccard_distance(schemas[i], schemas[j])\n",
    "\n",
    "X = np.arange(len(schemas)).reshape(-1, 1)\n",
    "DBSCAN(metric=jacc_metric, eps=0.1, min_samples=2).fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def dbscan(X):\n",
    "    return DBSCAN(metric=jacc_metric, eps=0.1, min_samples=2).fit_predict(X)\n",
    "\n",
    "\n",
    "def generate_cluster_dict(df_dict,cluster_function):\n",
    "    # Build Schema, Df and index lists\n",
    "    dfs = []\n",
    "    schemas = []\n",
    "    for name, df in df_dict.items():\n",
    "        dfs.append(name)\n",
    "        schemas.append(frozenset(df))\n",
    "\n",
    "    X = np.arange(len(schemas)).reshape(-1, 1)\n",
    "    \n",
    "    clusters = cluster_function(X)\n",
    "    \n",
    "    cluster_assigns = defaultdict(list)\n",
    "    \n",
    "    for i,df in enumerate(dfs):\n",
    "        cluster_assigns[clusters[i]].append(df)\n",
    "        \n",
    "    return cluster_assigns\n",
    "\n",
    "def new_clusters_for_noise(clusters): \n",
    "    if -1 in clusters:\n",
    "        noisy_points = clusters[-1]:\n",
    "        start_index = len(clusters)\n",
    "        for i, point in noisy_points:\n",
    "            clusters[start_index+i] = point\n",
    "\n",
    "        del(clusters[-1])\n",
    "    \n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {0: ['typeLoc__1.csv', 'locationRecode.csv'],\n",
       "             1: ['typeLoc.csv',\n",
       "              'areaCrime.csv',\n",
       "              'areaCrime__1.csv',\n",
       "              'crimesByMonth.csv',\n",
       "              'typeLoc__2.csv',\n",
       "              'crimes.csv',\n",
       "              'typeLoc__3.csv'],\n",
       "             -1: ['typeOutcome.csv']})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_cluster_dict(df_dict, dbscan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clustering\n",
    "\n",
    "clustering.write_clusters_to_file(generate_cluster_dict(df_dict, dbscan), 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
